#!/usr/bin/env python3

"""This script contains neural network architectures used in the RIS package.

William Jenkins, wjenkins [at] ucsd [dot] edu
Scripps Institution of Oceanography, UC San Diego
January 2021
"""

import torch
import torch.nn as nn

# I expirmented with this for an 8 second data lenght (200X97
# ======== This network is for data of dimension 100x87 (4 s) =================
class Encoder(nn.Module):
    """
    Description: Encoder layers of autoencoder model; encodes input data
    (spectrograms) into the latent feature space.
    Inputs:
        - Input data (spectrograms)
    Outputs:
        - Latent feature space data
    """
    def __init__(self,dataParameters = None):
        #print("Expirmenting with 8 second data dimensions!\n")
        #print("Did so by keeping 128 feature size and making the input 256*9")
        #print("warning this program is currently set up to modify output and input layers for the NN automatically to fit input data\n")
        #print("This is probably not ideal!\n")
        self.dataParameters = dataParameters
        super(Encoder, self).__init__()
        #he designed the stride so that each layer effectively shrinks the output by 2
        self.encoder = nn.Sequential(
            #1,8X256
            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=(2,2), padding=(1,1)),
            nn.Tanh(),
            #97X100
            nn.Conv2d(8, 16, kernel_size=(3,3), stride=(2,2), padding=1),
            nn.Tanh(),
            #48X50
            nn.Conv2d(16, 32, kernel_size=(3,3), stride=(2,2), padding=1),
            nn.Tanh(),
            #24X25
            nn.Conv2d(32, 64, kernel_size=(3,3), stride=(2,2), padding=1),
            nn.Tanh(),
            #12X12
            nn.Conv2d(64, 128, kernel_size=(3,3), stride=(2,2), padding=(1,1)),
            nn.Tanh(),
            #11,11
            nn.Flatten(),
            #this tells the network the number of input features and the number of output features
            #I guess that convolutional layers are not necessarily fully connected
            #3073 inputs and 9 outputs
            nn.Linear(128*4*7, 9),
            nn.Tanh() 
        )

    def forward(self, x):
        #print("encoder")
        x = self.encoder(x)
        """
        #debug encoder
        #1,8X256
        relu = nn.ReLU()
        print(x.shape)
        conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=(2,2), padding=(1,1))
        x=conv1(x)
        x = relu(x)
        print(x.shape)
        #97X200
        conv2=nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(2,2), padding=1)
        x=conv2(x)
        x = relu(x)
        print(x.shape)
        #48X100
        conv3=nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), stride=(2,2), padding=1)
        nn.ReLU(True)
        x=conv3(x)
        x = relu(x)
        print(x.shape)
        #24X50
        conv4=nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=(2,2), padding=1)
        nn.ReLU(True)
        x=conv4(x)
        x = relu(x)
        print(x.shape)
        #12X12
        #changed the stride on the last layer to be finer (1,1)
        conv5=nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(2,2), padding=(1,1))
        nn.ReLU(True)
        x=conv5(x)
        x = relu(x)
        print("5th convolution")
        print(x.shape)
        #11,11
        #nn.Flatten()
        #flatten x
        x = x.reshape(x.size(0), -1)
        print(x.shape)
        #this tells the network the number of input features and the number of output features
        #I guess that convolutional layers are not necessarily fully connected
        #3073 inputs and 9 outputs
        linear = nn.Linear(128*4*7, 9)
        nn.ReLU(True)
        x=linear(x)
        print(x.shape)
        print(self.encoder)
        print(x.shape)
        """
        return x


class Decoder(nn.Module):
    """
    Description: Decoder layers of autoencoder model; reconstructs encoder
    inputs using the latent features generated by the encoder.
    Inputs:
        - Latent space data
    Outputs:
        - Reconstructed data
    """
    #print("note that the decoder currently reconstructs to data size of 4 seconds")
    def __init__(self,dataParameters=None):
        self.dataParameters = dataParameters
        super(Decoder, self).__init__()
        self.latent2dec = nn.Sequential(
            nn.Linear(9, 128*4*7),
            #nn.Tanh() #chuck things that it is a good idea to drop the final tanh here
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, kernel_size=(3,3), stride=(2,2), padding=(1,0)), # <---- Experimental
            nn.Tanh(),  # <---- Experimental
            nn.ConvTranspose2d(64, 32, kernel_size=(3,3), stride=(2,2), padding=(1,1)),
            nn.Tanh(),
            nn.ConvTranspose2d(32, 16, kernel_size=(3,3), stride=(2,2), padding=(1,1)),
            nn.Tanh(),
            nn.ConvTranspose2d(16, 8, kernel_size=(3,3), stride=(2,2), padding=(1,1)),
            nn.Tanh(),
            nn.ConvTranspose2d(8, 1, kernel_size=(3,3), stride=(2,2), padding=(1,1)),
        )

    def forward(self, x):
        
        
        x = self.latent2dec(x)
        #print(x.shape)
        #the -1 is to select the last one 
        x = x.view(-1, 128, 4, 7)
        #print(x.shape)
        x = self.decoder(x)
        print(x.shape)
        #print(x[:,:,:,25:].shape)
        return x[:,:,:,25:]


class AEC(nn.Module):
    """
    Description: Autoencoder model; combines encoder and decoder layers.
    Inputs:
        - Parameters (so that the output data sizes are generated correctly)
        - Input data (spectrograms)
    Outputs:
        - Reconstructed data
        - Latent space data
    """
    def __init__(self,dataParameters=None):
        self.dataParameters = dataParameters
        super(AEC, self).__init__()
        self.encoder = Encoder()
        self.decoder = Decoder()

    def forward(self, x):
        z = self.encoder(x)
        x = self.decoder(z)
        return x, z


def init_weights(m):
    """
    Description: Initializes weights with the Glorot Uniform distribution.
    Inputs:
        - Latent space data
    Outputs:
        - Reconstructed data
    """
    if type(m) in [nn.Linear, nn.Conv2d, nn.ConvTranspose2d]:
        torch.nn.init.xavier_uniform_(m.weight)
        m.bias.data.fill_(0.01)


class ClusteringLayer(nn.Module):
    """
    Description: Generates soft cluster assignments using latent features as
    input.
    Arguments:
        - n_clusters: User-defined
        - n_features: Must match output dimension of encoder.
        - alpha: Exponential factor (default: 1.0)
        - weights: Initial values for the cluster centroids
    Inputs:
        Encoded data (output of encoder)
    Outputs:
        Soft cluster assignments
    """
    def __init__(self, n_clusters, n_features=9, alpha=1.0, weights=None):
        super(ClusteringLayer, self).__init__()
        self.n_features = n_features
        self.n_clusters = n_clusters
        self.alpha = alpha
        if weights is None:
            initial_weights = torch.zeros(
                self.n_clusters, self.n_features, dtype=torch.float
            )
            nn.init.xavier_uniform_(initial_weights)
        else:
            initial_weights = weights
        self.weights = nn.Parameter(initial_weights)

    def forward(self, x):
        x = x.unsqueeze(1) - self.weights
        x = torch.mul(x, x)
        x = torch.sum(x, dim=2)
        x = 1.0 + (x / self.alpha)
        x = 1.0 / x
        x = x ** ((self.alpha +1.0) / 2.0)
        x = torch.t(x) / torch.sum(x, dim=1)
        x = torch.t(x)
        return x


class DEC(nn.Module):
    """Description: Deep Embedded Clustering Model; combines autoencoder with
    clustering layer to generate end-to-end deep embedded clustering neural
    network model.

    Parameters
    ----------
    n_clusters : int
        Number of clusters

    Returns
    -------
    q : array
        Soft cluster assignments

    x : array
        Reconstructed data

    z : array
        Latent space data
    """
    def __init__(self, n_clusters):
        super(DEC, self).__init__()
        self.n_clusters = n_clusters
        self.encoder = Encoder()
        self.decoder = Decoder()
        self.clustering = ClusteringLayer(self.n_clusters)

    def forward(self, x):
        z = self.encoder(x)
        x = self.decoder(z)
        q = self.clustering(z)
        return q, x, z
